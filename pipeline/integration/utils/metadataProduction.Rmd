---
title: Species metadata description
output: html_document
editor_options: 
  chunk_output_type: console
---

``` {r, dataImport, echo = FALSE}
library(dplyr)
library(ggplot2)
library(sf)
library(inlabru)
library(gridExtra)
library(tidyterra)

# Combine into one data frame and add date accessed
processedDataCompiled$dateAccessed <- Sys.Date()
processedDataCompiled$redListStatus <- ifelse(processedDataCompiled$acceptedScientificName %in% redListSpecies$validSpecies, TRUE, FALSE)

# Turn geometry column to latitude and longitude
processedDataDF <- st_drop_geometry(processedDataCompiled)
processedDataDF[,c("decimalLongitude", "decimalLatitude")] <- st_coordinates(processedDataCompiled)

```

# Biodiversity mapping

The following pdf gives a description of the data used in the pipeline run that corresponds to the folder this document resides in.
It should be used as a guide for anyone who wants to know more about the data used in the corresponding outputs (maps and datasets)
and/or would like to replicate the data.

We begin with basic information about the pipeline run.


``` {r, basicInfo, echo = FALSE}

region <- attr(speciesDataList, "region")
level <- attr(speciesDataList, "level")
focalTaxa <- unique(focalTaxon$taxa)
totalSpecies <- length(unique(processedDataCompiled$acceptedScientificName))
downloadKey <- readRDS(paste0("../../../", folderName, "/downloadKey.RDS"))
infoNames <- c("Date",
               "Taxa",
               "Region type",
               "Region code",
               "Total species",
               "Total datasets used", 
               "DOI")
info <- c(dateAccessed, paste(focalTaxa, collapse = ", "), level,  paste(region, collapse = ", "), totalSpecies,
          length(unique(processedDataDF$dsName)), downloadKey$doi)
basicInfo <- data.frame(Characteristic = infoNames, Value = info)
knitr::kable(basicInfo)
```

In addition to the above, data was downloaded with a maximum uncertainty regarding coordinates of 100 metres.

The following shows total number of species per taxa and per dataset from the initial download from GBIF and ANO.
Note that only the top 10 datasets are shown. A full list of observations per dataset per taxa as well as observations per species can be found in the appendices.

``` {r, dataTables, echo = FALSE, message = FALSE}
# Get number of species per taxa
taxaTable <- processedDataDF %>%
  dplyr::select(taxa, acceptedScientificName, redListStatus) %>%
  distinct() %>%
  group_by(taxa, redListStatus) %>%
  tally()
taxaTable2 <- taxaTable %>%
  group_by(taxa) %>%
  summarise(species = sum(n),
            redListedSpecies = sum(n[redListStatus == TRUE]))

datasetTable <- processedDataDF %>%
  group_by(dsName, dataType, redListStatus) %>%
  tally()
datasetTable2 <- datasetTable %>%
  group_by(dsName, dataType) %>%
  summarise(observations = sum(n),
            redListedObservations = sum(n[redListStatus == TRUE])) %>%
  arrange(-observations)


knitr::kable(
  list(taxaTable2
       ,datasetTable2[1:min(nrow(datasetTable2), 10),]
  ), 
  valign = 't'
)

```

The following gives species richness for observations across the surveyed region by taxa.

``` {r, maps, echo = FALSE, message = FALSE, fig.fullwidth=TRUE}
plotList <- list()
for (i in 1:length(focalTaxa)) {
  speciesRichnessAggregated <- aggregate(allSpeciesRichness$rasters[[focalTaxa[i]]], fact = 4)
  
  speciesRichnessPlot <- ggplot(regionGeometry) +
    geom_spatraster(data = speciesRichnessAggregated) +
    geom_sf(fill = "NA") +
    scale_fill_gradient(low = 'white', high = 'red', na.value=NA) +
    theme_bw() +
    ggtitle(focalTaxa[i])
  print(speciesRichnessPlot)
}


```


\newpage

```{r, sourceFunctionalGroups, echo = FALSE}
source("../../../functions/joinFunctionalGroups.R")
focalSpecies <- read.csv(paste0("../../../", folderName, "/focalTaxa.csv"))
```

The following gives spatial density for observations across the surveyed region by taxa.
```{r, joinFuncgroups_plot_observations, echo = FALSE}
focalTaxa <- unique(na.omit(processedDataCompiled$taxa)) 

for (i in seq_along(focalTaxa)) {
  focalTaxaGroup <- focalTaxa[i]
  processedDataShortened <- processedDataCompiled[processedDataCompiled$taxa == focalTaxaGroup,]
  # Combine species by functionalGroup if requested
  # functional groups in species with data for focal taxonomic group
  focalSpeciesWithData <- focalSpecies[focalSpecies$key %in% processedDataShortened$taxonKeyProject &  # species with data
                                        focalSpecies$taxa %in% focalTaxaGroup,]  # and of focal taxa (in case same species in different taxa)
  # if any species are to be modelled as functional groups
  if(any(!is.na(focalSpeciesWithData$functionalGroup) & 
           focalSpeciesWithData$functionalGroup != "")){
    # update data
    processedDataShortenedFunc <- joinFunctionalGroups(speciesData = processedDataShortened,
        focalTaxon = focalSpeciesWithData) %>%
        # replace ungrouped species with "ungrouped"
        mutate(simpleScientificName = ifelse(scientificName == simpleScientificName, "Ungrouped", simpleScientificName))

    rows <- sample(seq(nrow(processedDataShortenedFunc)), 
                   min(nrow(processedDataShortenedFunc), 1000)) # max 1,000 data points
    # plot
    p <- ggplot(regionGeometry) +
          geom_sf() +
          geom_sf(data = processedDataShortenedFunc[rows,], colour = 'blue', size = 0.1) +
          facet_wrap(~simpleScientificName) +
          ggtitle(focalTaxaGroup)
  } else {
    rows <- sample(seq(nrow(processedDataShortened)), 
                   min(nrow(processedDataShortened), 1000)) # max 1,000 data points
    # plot
    p <- ggplot(regionGeometry) +
          geom_sf() +
          geom_sf(data = processedDataShortened[rows,], colour = 'blue', size = 0.1) +
      ggtitle(focalTaxaGroup)
  }
  print(p)
}
```


\newpage

## Appendices

### Appendix 1

The tables below give further information on the observations used for our pipeline run.


``` {r, appendix, echo = FALSE}
datasetTaxaTable <- processedDataDF %>%
  group_by(taxa, dsName) %>%
  tally(name = "Observations") %>%
  arrange(taxa, -Observations)

datatypeTable <- processedDataDF %>%
  group_by(taxa, dataType) %>%
  tally(name = "Observations") %>%
  arrange(taxa, -Observations)

knitr::kable(
  datasetTaxaTable, 
  valign = 't',
  caption = 'Total numbers of observations used in pipeline run for each dataset by taxa.'
)

knitr::kable(
  datatypeTable, 
  valign = 't',
  caption = 'Total numbers of observations used in pipeline run for each data type by taxa.'
)

```
