---
title: Species metadata description
output: html_document
editor_options: 
  chunk_output_type: console
---

``` {r, dataImport, echo = FALSE}
library(dplyr)
library(ggplot2)
library(sf)
library(inlabru)
library(gridExtra)
library(rgbif)
library(tidyterra)
library(knitr)
library(kableExtra)

# Combine into one data frame and add date accessed
processedDataCompiled$dateAccessed <- Sys.Date()
processedDataCompiled$redListStatus <- ifelse(processedDataCompiled$acceptedScientificName %in% redListSpecies$validSpecies, TRUE, FALSE)

# Turn geometry column to latitude and longitude
processedDataDF <- st_drop_geometry(processedDataCompiled)
processedDataDF[,c("decimalLongitude", "decimalLatitude")] <- st_coordinates(processedDataCompiled)

```

# Biodiversity mapping

The following pdf gives a description of the data used in the pipeline run that corresponds to the folder this document resides in.

It should be used as a guide for anyone who wants to know more about the data used in the corresponding outputs (maps and datasets) and/or would like to replicate the data.

We begin with basic information about the pipeline run.


``` {r, basicInfo, echo = FALSE}

focalTaxa <- unique(focalTaxon$taxa)
totalSpecies <- length(unique(processedDataCompiled$acceptedScientificName))
downloadKey <- readRDS(paste0("../../../", folderName, "/downloadKey.RDS"))
infoNames <- c("Date pipeline initiated",
               "Date species data processed",
               "Taxa",
               "Taxon key(s)",
               "Cutoff year",
               "Region type",
               "Region code",
               "Total species",
               "Total datasets used",
               "Resolution (metres)",
               "Citation")
infoDescription <- c("The date when the GBIF download was initiated.",
                     "The date when source data from datasets requiring further processing was downloaded.",
                     "Taxa used in the pipeline run.",
                     "GBIF's code for the taxa used in the pipeline run.",
                     "The year from which all data is taken.",
                     "The spatial level used (country, county, municipality or boxed area).",
                     "The region within which data was collected.",
                     "Total species present in the processed data.",
                     "Total datasets used in the processed data.",
                     "Resolution to which environmental covariates were aggregated.",
                     "Relevant citation for the initial data download.")
info <- c(dateAccessed, as.character(Sys.Date()), paste(focalTaxa, collapse = ", "), paste(focalTaxon$key, collapse = ", "), yearToStart, level,  paste(region, collapse = ", "), totalSpecies,
          length(unique(processedDataDF$dsName)), res, gbif_citation(downloadKey$key)$download)
basicInfo <- data.frame(Characteristic = infoNames, Value = info, Description = infoDescription)
kbl(basicInfo) %>%
  kable_styling(bootstrap_options = "striped") %>%
  column_spec(2, width = "10em")
```

The following shows the environmental covariates that we used, as well as extra information regarding:

- **Categorical**: Whether or not the covariate what a categorical covariate (one map showing many different categories at different locations) or a continuous covariate (one covariate ranged on a numerical scale).

- **Quadratic**: The relationship between some species presences and the covariate may not be linear. For example as temperature rises some plants may benefit, but once the temperature goes beyond a certain point they may start to suffer. We accoutn for this by adding a quadratic term to our equation for certain covariates.

``` {r, envInfo, echo = FALSE}

covariates <- read.csv(paste0("../../../", folderName, "/focalCovariates.csv"))
covariateNames <- focalTaxon[covariates$parameters[covariates$parameters %in% colnames(focalTaxon)]]
covariatesUsed <- colnames(covariateNames)[unlist(c(covariateNames[1,]))]
categorical <- covariates$categorical[match(covariatesUsed, covariates$parameters)]
squared <- covariates$quadratic[match(covariatesUsed, covariates$parameters)]
covariatesUsed <- gsub("_", " ", paste0(toupper(substr(covariatesUsed, 1, 1)), substr(covariatesUsed, 2, nchar(covariatesUsed))))
categorical <- ifelse(categorical, "Categorical", "Continuous")
squared <- ifelse(squared, "Yes", "No")
covTable <- data.frame(Covariates = covariatesUsed, Categorical = categorical, Quadratic = squared)
kbl(covTable) %>%
  kable_styling(bootstrap_options = "striped") 
```


The following shows total number of species per taxa and per dataset from the initial download from GBIF and ANO.
Note that only the top 10 datasets are shown. A full list of observations per dataset per taxa as well as observations per species can be found in the appendices.

Please note that these represent the data used before final filtering for a) species with insufficient data and b) datasets with insufficient data.

``` {r, dataTables, echo = FALSE, message = FALSE}
# Get number of species per taxa
taxaTable <- processedDataDF %>%
  dplyr::select(taxa, acceptedScientificName, redListStatus) %>%
  distinct() %>%
  group_by(taxa, redListStatus) %>%
  tally()
taxaTable2 <- taxaTable %>%
  group_by(taxa) %>%
  summarise(species = sum(n),
            redListedSpecies = sum(n[redListStatus == TRUE]))

datasetTable <- processedDataDF %>%
  group_by(dsName, dataType, redListStatus) %>%
  tally()
datasetTable2 <- datasetTable %>%
  group_by(dsName, dataType) %>%
  summarise(observations = sum(n),
            redListedObservations = sum(n[redListStatus == TRUE])) %>%
  arrange(-observations)


knitr::kable(
  list(taxaTable2
       ,datasetTable2[1:min(nrow(datasetTable2), 10),]
  ), 
  valign = 't'
)

```

The following gives observed species richness across the surveyed region by taxa. 

``` {r, maps, echo = FALSE, message = FALSE, fig.fullwidth=TRUE}
plotList <- list()
for (i in 1:length(focalTaxa)) {
  speciesRichnessAggregated <- aggregate(allSpeciesRichness$rasters[[focalTaxa[i]]], fact = 4)
  
  speciesRichnessPlot <- ggplot(regionGeometry) +
    geom_spatraster(data = speciesRichnessAggregated) +
    geom_sf(fill = "NA") +
    scale_fill_gradient(low = 'white', high = 'red', na.value=NA) +
    theme_bw() +
    ggtitle(focalTaxa[i]) + labs(fill = "Total species\nobserved", 
                                 caption = paste0("Data aggregated to pixels of ",(res/1000 * 4)^2, "square km"))
  print(speciesRichnessPlot)
}


```


\newpage

```{r, sourceFunctionalGroups, echo = FALSE}
source("../../../functions/joinFunctionalGroups.R")
focalSpecies <- read.csv(paste0("../../../", folderName, "/focalTaxa.csv"))
```


\newpage

## Appendices

### Appendix 1

The tables below give further information on the observations used for our pipeline run.


``` {r, appendix, echo = FALSE}
datasetTaxaTable <- processedDataDF %>%
  group_by(taxa, dsName) %>%
  tally(name = "Observations") %>%
  arrange(taxa, -Observations)

datatypeTable <- processedDataDF %>%
  group_by(taxa, dataType) %>%
  tally(name = "Observations") %>%
  arrange(taxa, -Observations)

knitr::kable(
  datasetTaxaTable, 
  valign = 't',
  caption = 'Total numbers of observations used in pipeline run for each dataset by taxa.'
)

knitr::kable(
  datatypeTable, 
  valign = 't',
  caption = 'Total numbers of observations used in pipeline run for each data type by taxa.'
)

```
